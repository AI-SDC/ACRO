{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a9bf0e-aff8-48ee-a4a8-0cb889aac3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sfi import Data, Macro, Missing, SFIToolkit, Scalar\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b8711d6-9028-4bc1-bc03-2796467673c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'acro.acro_stata_parser' from '/Users/j4-smith/GitHub/AI-SDC/ACRO/stata/../acro/acro_stata_parser.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import acro\n",
    "from acro import utils\n",
    "from acro import stata_config\n",
    "import pandas as pd\n",
    "from acro import acro_stata_parser\n",
    "from importlib import reload\n",
    "import pytest\n",
    "\n",
    "reload(acro_stata_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26b461fd-5608-4b48-aec5-b852bdd40b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_acrohandler(command, varlist, exclusion, exp, weights, options):\n",
    "    if debug:\n",
    "        outline = \"in python acrohandler function: \"\n",
    "        outline += f\"command = {command} \"\n",
    "        outline += f\"varlist={varlist} \"\n",
    "        outline += f\"if = {exclusion} \"\n",
    "        outline += f\"exp = {exp} \"\n",
    "        outline += f\"weights={weights} \"\n",
    "        outline += f\"options={options} \"\n",
    "        print(outline)\n",
    "\n",
    "    # make data object\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    the_data = pd.read_stata(path)\n",
    "    # print(f'in dummy acrohandler dataset has size {the_data.shape}')\n",
    "\n",
    "    # now do the acro part\n",
    "    acro_outstr = acro_stata_parser.parse_and_run(\n",
    "        the_data, command, varlist, exclusion, exp, weights, options\n",
    "    )\n",
    "\n",
    "    return acro_outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0711d1d2-7025-42ab-af95-c8c2ec3ef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy string to copy/paste\n",
    "# command='',varlist='',exclusion='',exp='',weights='',options=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e67745e9-1713-4d81-94a2-36ab8e98222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_apply_stata_ifstmt(data):\n",
    "    \"\"\"Tests that if statements work for selection.\"\"\"\n",
    "    ifstring = \"year!=2013\"\n",
    "    all_list = list(data[\"year\"].unique())\n",
    "    smaller = acro_stata_parser.apply_stata_ifstmt(ifstring, data)\n",
    "    all_list.remove(2013)\n",
    "    assert list(smaller[\"year\"].unique()) == all_list\n",
    "    ifstring2 = \"year != 2013 & year <2015\"\n",
    "    all_list.remove(2015)\n",
    "    smaller2 = acro_stata_parser.apply_stata_ifstmt(ifstring2, data)\n",
    "    assert list(smaller2[\"year\"].unique()) == all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7207b74b-9ea5-4ebf-9bdf-97a87cbdefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( year != 2013)\n",
      "( year  !=  2013 ) & ( year  < 2015)\n"
     ]
    }
   ],
   "source": [
    "# make data object\n",
    "path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "the_data = pd.read_stata(path)\n",
    "test_apply_stata_ifstmt(the_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c1d5f-e798-4eb5-9484-888e1c95edc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d36fc-f6be-4650-b5a7-9d1956ffdb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd78990-10c6-43a8-bc96-aa9f44c2a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cae0e6-ced9-4620-831a-c7b40d47a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_acro_init() -> str:\n",
    "    assert isinstance(stata_config.stata_acro, ACRO)\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"init\", varlist=\"\", exclusion=\"\", exp=\"\", weights=\"\", options=\"\"\n",
    "    )\n",
    "    assert (\n",
    "        ret == \"acro analysis session created\\n\"\n",
    "    ), f\"wrong string for acro init: {ret}\\n\"\n",
    "    errmsg = f\"wrong type for stata_config.stata_acro:{type(stata_config.stata_acro)}\"\n",
    "    assert isinstance(stata_config.stata_acro, acro.ACRO), errmsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a43d071-29f9-4273-96ff-3b8ebae86c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:version: 0.4.3\n",
      "INFO:acro:config: {'safe_threshold': 10, 'safe_dof_threshold': 10, 'safe_nk_n': 2, 'safe_nk_k': 0.9, 'safe_pratio_p': 0.1, 'check_missing_values': False}\n",
      "INFO:acro:automatic suppression: False\n"
     ]
    }
   ],
   "source": [
    "test_stata_acro_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8a94c8-2f8d-4908-a831-7d56ed78664b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_parse_table_details():\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    the_data = pd.read_stata(path)\n",
    "\n",
    "    varlist = [\"survivor\", \"grant_type\", \"year\"]\n",
    "    varnames = the_data.columns\n",
    "    options = \"by(grant_type) \" \"contents(mean sd inc_activity)\" \"suppress \" \"nototals\"\n",
    "    details = acro_stata_parser.parse_table_details(varlist, varnames, options)\n",
    "\n",
    "    errstring = f\" rows {details['rowvars']} should be ['grant_type','survivor']\"\n",
    "    assert details[\"rowvars\"] == [\"grant_type\", \"survivor\"], errstring\n",
    "\n",
    "    errstring = f\" cols {details['colvars']} should be ['year','grant_type']\"\n",
    "    assert details[\"colvars\"] == [\"year\", \"grant_type\"], errstring\n",
    "\n",
    "    errstring = f\" aggfunctions {details['aggfuncs']} should be ['mean','sd']\"\n",
    "    assert details[\"aggfuncs\"] == [\"mean\", \"sd\"], errstring\n",
    "\n",
    "    errstring = f\" values {details['values']} should be ['inc_activity']\"\n",
    "    assert details[\"values\"] == [\"inc_activity\"], errstring\n",
    "\n",
    "    assert not details[\"totals\"], \"totals should be False\"\n",
    "    assert details[\"suppress\"], \"supress should be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b8dc82-01a6-4a87-ac71-fc72beb8c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parse_table_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee231dc-b817-48ca-8c92-71fa3b25e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_table() -> str:\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    df = pd.read_stata(path)\n",
    "    # correct = pd.crosstab(index=df[\"survivor\"], columns=df[\"grant_type\"]).to_string()\n",
    "    correct = (\n",
    "        \"------------------------------------|\\n\"\n",
    "        \"grant_type     |G   |N    |R    |R/G|\\n\"\n",
    "        \"survivor       |    |     |     |   |\\n\"\n",
    "        \"------------------------------------|\\n\"\n",
    "        \"Dead in 2015   |18  |  0  |282  | 0 |\\n\"\n",
    "        \"Alive in 2015  |72  |354  |144  |48 |\\n\"\n",
    "        \"------------------------------------|\\n\"\n",
    "    )\n",
    "    ret = dummy_acrohandler(\n",
    "        \"table\",\n",
    "        \"survivor grant_type\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"nototals\",\n",
    "    )\n",
    "    ret = ret.replace(\"NaN\", \"0\")\n",
    "    ret = ret.replace(\".0\", \"\")\n",
    "    assert ret.split() == correct.split(), f\"got\\n{ret}\\n expected\\n{correct}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da1b56a-19e4-4380-8364-a52092607ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:get_summary(): fail; threshold: 2 cells may need suppressing; \n",
      "INFO:acro:outcome_df:\n",
      "---------------------------------------------------|\n",
      "grant_type    |G   |N            |R   |R/G         |\n",
      "survivor      |    |             |    |            |\n",
      "---------------------------------------------------|\n",
      "Dead in 2015  | ok | threshold;  | ok | threshold; |\n",
      "Alive in 2015 | ok |          ok | ok |          ok|\n",
      "---------------------------------------------------|\n",
      "\n",
      "INFO:acro:records:add(): output_0\n"
     ]
    }
   ],
   "source": [
    "test_simple_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72865fb-5bef-4aba-958a-1a19b52901b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_linregress():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"regress\",\n",
    "        varlist=\" inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "\n",
    "    tokens = ret.split()\n",
    "    idx = tokens.index(\"Residuals:\")\n",
    "    val = int(tokens[idx + 1])\n",
    "    assert val == 807, f\"{val} should be 807\"\n",
    "    idx = tokens.index(\"R-squared:\")\n",
    "    val = float(tokens[idx + 1])\n",
    "    assert val == pytest.approx(0.894, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09551996-933e-4713-8a25-9a5047a7235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:ols() outcome: pass; dof=807.0 >= 10\n",
      "INFO:acro:records:add(): output_1\n"
     ]
    }
   ],
   "source": [
    "test_stata_linregress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "022b4922-2026-4723-aba5-762a70a08239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_probit():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"probit\",\n",
    "        varlist=\" survivor inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "\n",
    "    # assert False,f'\\n{ret}\\n'\n",
    "    tokens = ret.split()\n",
    "    idx = tokens.index(\"Residuals:\")\n",
    "    val = tokens[idx + 1]\n",
    "    if val[-1] == \"|\":\n",
    "        val = val[0:-1]\n",
    "    assert float(val) == pytest.approx(806.0, 0.01), f\"{val} should be 806\"\n",
    "    idx = tokens.index(\"R-squ.:\")\n",
    "    val = tokens[idx + 1]\n",
    "    if val[-1] == \"|\":\n",
    "        val = val[0:-1]\n",
    "    val = float(val)\n",
    "    assert val == pytest.approx(0.208, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "356bc420-8042-4441-84ce-369507b136e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:probit() outcome: pass; dof=806.0 >= 10\n",
      "INFO:acro:records:add(): output_25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497218\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "test_stata_probit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66750a25-148d-4d00-bd69-3e82a18e7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_logit():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"logit\",\n",
    "        varlist=\" survivor inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    # assert False,f'\\n{ret}\\n'\n",
    "    tokens = ret.split()\n",
    "    idx = tokens.index(\"Residuals:\")\n",
    "    val = tokens[idx + 1]\n",
    "    if val[-1] == \"|\":\n",
    "        val = val[0:-1]\n",
    "    assert float(val) == pytest.approx(806.0, 0.01), f\"{val} should be 806\"\n",
    "    idx = tokens.index(\"R-squ.:\")\n",
    "    val = tokens[idx + 1]\n",
    "    if val[-1] == \"|\":\n",
    "        val = val[0:-1]\n",
    "    val = float(val)\n",
    "    assert val == pytest.approx(0.214, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c3a67b5-765f-4a1e-87a8-f5fd904912bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:logit() outcome: pass; dof=806.0 >= 10\n",
      "INFO:acro:records:add(): output_26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493788\n",
      "         Iterations 12\n"
     ]
    }
   ],
   "source": [
    "reload(acro_stata_parser)\n",
    "test_stata_logit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "088eb32a-fbec-4ab4-9955-93b20a659bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_print_outputs():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"print_outputs\",\n",
    "        varlist=\" inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    assert len(ret) == 0, \"return string should  be empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec339b36-57eb-4f39-9d25-3b4f0117e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stata_print_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a9a34e6-3b72-467d-b265-e1c6677ea537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_finalise():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"finalise\",\n",
    "        varlist=\"\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    correct = \"outputs and stata_out.json written\\n\"\n",
    "    assert ret == correct, f\"returned string {ret} should be {correct}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edf066a6-029b-4934-a233-f2352b698a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:records:\n",
      "uid: output_0\n",
      "status: fail\n",
      "type: table\n",
      "properties: {'method': 'crosstab'}\n",
      "sdc: {'summary': {'suppressed': False, 'negative': 0, 'missing': 0, 'threshold': 2, 'p-ratio': 0, 'nk-rule': 0}, 'cells': {'negative': [], 'missing': [], 'threshold': [[0, 1], [0, 3]], 'p-ratio': [], 'nk-rule': []}}\n",
      "command: safe_output = stata_acro.crosstab(\n",
      "summary: fail; threshold: 2 cells may need suppressing; \n",
      "outcome: grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "output: [grant_type      G    N    R  R/G\n",
      "survivor                        \n",
      "Dead in 2015   18    0  282    0\n",
      "Alive in 2015  72  354  144   48]\n",
      "timestamp: 2023-08-14T16:06:03.132855\n",
      "comments: []\n",
      "exception: \n",
      "\n",
      "The status of the record above is: fail.\n",
      "Please explain why an exception should be granted.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:records:outputs written to: stata_out\n"
     ]
    }
   ],
   "source": [
    "test_stata_finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3244415-990f-461b-8618-51844ac4cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find_brace_contents():\n",
    "    options = \"by(grant_type) \" \"contents(mean sd inc_activity)\" \"suppress \" \"nototals\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"by\", options)\n",
    "    assert res == True\n",
    "    assert substr == \"grant_type\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"contents\", options)\n",
    "    assert res == True\n",
    "    assert substr == \"mean sd inc_activity\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"foo\", options)\n",
    "    assert res == False\n",
    "    assert substr == \"foo not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340292-cbc5-4ff8-96f4-dddd3ade650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_find_brace_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1f74b-2c82-4673-861a-ff749260204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unsupported_formatting_options():\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    df = pd.read_stata(path)\n",
    "    format_string = \"acro does not currently support table formatting commands.\"\n",
    "    correct = pd.crosstab(index=df[\"survivor\"], columns=df[\"grant_type\"]).to_string()\n",
    "    for bad_option in [\n",
    "        \"cellwidth\",\n",
    "        \"csepwidth\",\n",
    "        \"stubwidth\",\n",
    "        \"scsepwidth\",\n",
    "        \"center\",\n",
    "        \"left\",\n",
    "    ]:\n",
    "        ret = dummy_acrohandler(\n",
    "            \"table\",\n",
    "            \"survivor grant_type\",\n",
    "            exclusion=\"\",\n",
    "            exp=\"\",\n",
    "            weights=\"\",\n",
    "            options=f\"{bad_option} nototals\",\n",
    "        )\n",
    "\n",
    "        rets = ret.split(\"\\n\", 1)\n",
    "        assert len(rets) == 2, \"table should have warning preprended\"\n",
    "        errmsg = f\"first line {rets[0]} should be {format_string}\"\n",
    "        assert rets[0] == format_string, errmsg\n",
    "        ret = rets[1]\n",
    "        ret = ret.replace(\"NaN\", \"0\")\n",
    "        ret = ret.replace(\".0\", \"\")\n",
    "        assert ret.split() == correct.split(), f\"got\\n{ret}\\n expected\\n{correct}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93d307-dc11-4766-ac91-c3c580ff0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unsupported_formatting_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a11dab-f605-479b-b5c9-6cbe61280fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b257928-1819-40e4-902a-81c863fbb608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a9a58-ef98-4d05-8116-43cc1be48eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint1",
   "language": "python",
   "name": "sprint1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

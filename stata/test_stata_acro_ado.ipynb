{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca3cde7f-81ff-43ea-a24b-682ecc320b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'acro_stata_parser' from '/Users/j4-smith/GitHub/AI-SDC/ACRO/stata/acro_stata_parser.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sfi import Data, Macro, Missing, SFIToolkit, Scalar\n",
    "import os\n",
    "import acro\n",
    "import pandas as pd\n",
    "import acro_stata_parser\n",
    "from importlib import reload\n",
    "import pytest\n",
    "\n",
    "reload(acro_stata_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b461fd-5608-4b48-aec5-b852bdd40b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_acrohandler(command, varlist, exclusion, exp, weights, options):\n",
    "    global myacro\n",
    "    if debug:\n",
    "        outline = \"in python acrohandler function: \"\n",
    "        outline += f\"command = {command} \"\n",
    "        outline += f\"varlist={varlist} \"\n",
    "        outline += f\"if = {exclusion} \"\n",
    "        outline += f\"exp = {exp} \"\n",
    "        outline += f\"weights={weights} \"\n",
    "        outline += f\"options={options} \"\n",
    "        print(outline)\n",
    "\n",
    "    # make data object\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    the_data = pd.read_stata(path)\n",
    "    # print(f'in dummy acrohandler dataset has size {the_data.shape}')\n",
    "\n",
    "    # now do the acro part\n",
    "    acro_outstr = acro_stata_parser.parse_and_run(\n",
    "        the_data, command, varlist, exclusion, exp, weights, options\n",
    "    )\n",
    "\n",
    "    return acro_outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0711d1d2-7025-42ab-af95-c8c2ec3ef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy string to copy/paste\n",
    "# command='',varlist='',exclusion='',exp='',weights='',options=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cd78990-10c6-43a8-bc96-aa9f44c2a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "myacro = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43cae0e6-ced9-4620-831a-c7b40d47a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_acro_init() -> str:\n",
    "    global myacro\n",
    "    assert isinstance(myacro, str)\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"init\", varlist=\"\", exclusion=\"\", exp=\"\", weights=\"\", options=\"\"\n",
    "    )\n",
    "    assert (\n",
    "        ret == \"acro analysis session created\\n\"\n",
    "    ), f\"wrong string for acro init: {ret}\\n\"\n",
    "    # assert isinstance(myacro,acro.ACRO),f'wrong type for myacro:{type(myacro)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a43d071-29f9-4273-96ff-3b8ebae86c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:config: {'safe_threshold': 10, 'safe_dof_threshold': 10, 'safe_nk_n': 2, 'safe_nk_k': 0.9, 'safe_pratio_p': 0.1, 'check_missing_values': False}\n"
     ]
    }
   ],
   "source": [
    "test_stata_acro_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc8a94c8-2f8d-4908-a831-7d56ed78664b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_parse_table_details():\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    the_data = pd.read_stata(path)\n",
    "\n",
    "    varlist = [\"survivor\", \"grant_type\", \"year\"]\n",
    "    varnames = the_data.columns\n",
    "    options = \"by(grant_type) \" \"contents(mean sd inc_activity)\" \"suppress \" \"nototals\"\n",
    "    details = acro_stata_parser.parse_table_details(varlist, varnames, options)\n",
    "\n",
    "    errstring = f\" rows {details['rowvars']} should be ['grant_type','survivor']\"\n",
    "    assert details[\"rowvars\"] == [\"grant_type\", \"survivor\"], errstring\n",
    "\n",
    "    errstring = f\" cols {details['colvars']} should be ['year','grant_type']\"\n",
    "    assert details[\"colvars\"] == [\"year\", \"grant_type\"], errstring\n",
    "\n",
    "    errstring = f\" aggfunctions {details['aggfuncs']} should be ['mean','sd']\"\n",
    "    assert details[\"aggfuncs\"] == [\"mean\", \"sd\"], errstring\n",
    "\n",
    "    errstring = f\" values {details['values']} should be ['inc_activity']\"\n",
    "    assert details[\"values\"] == [\"inc_activity\"], errstring\n",
    "\n",
    "    assert not details[\"totals\"], \"totals should be False\"\n",
    "    assert details[\"suppress\"], \"supress should be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71b8dc82-01a6-4a87-ac71-fc72beb8c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parse_table_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee231dc-b817-48ca-8c92-71fa3b25e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_table() -> str:\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    df = pd.read_stata(path)\n",
    "    correct = pd.crosstab(index=df[\"survivor\"], columns=df[\"grant_type\"]).to_string()\n",
    "    ret = dummy_acrohandler(\n",
    "        \"table\",\n",
    "        \"survivor grant_type\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"nototals\",\n",
    "    )\n",
    "    ret = ret.replace(\"NaN\", \"0\")\n",
    "    ret = ret.replace(\".0\", \"\")\n",
    "    assert ret.split() == correct.split(), f\"got\\n{ret}\\n expected\\n{correct}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da1b56a-19e4-4380-8364-a52092607ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_0\n"
     ]
    }
   ],
   "source": [
    "test_simple_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e72865fb-5bef-4aba-958a-1a19b52901b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_linregress():\n",
    "    global myacro\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"regress\",\n",
    "        varlist=\" inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    ret = ret.replace(\"\\n\", \",\")\n",
    "    tokens = ret.split(\",\")\n",
    "    idx = tokens.index(\"Df Residuals:    \")\n",
    "    val = int(tokens[idx + 1])\n",
    "    assert val == 807, f\"{val} should be 807\"\n",
    "    idx = tokens.index(\"  R-squared:         \")\n",
    "    val = float(tokens[idx + 1])\n",
    "    assert val == pytest.approx(0.894, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09551996-933e-4713-8a25-9a5047a7235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:ols() outcome: pass; dof=807.0 >= 10\n",
      "INFO:acro::records:add(): output_1\n"
     ]
    }
   ],
   "source": [
    "test_stata_linregress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "022b4922-2026-4723-aba5-762a70a08239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_probit():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"probit\",\n",
    "        varlist=\" survivor inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    ret = ret.replace(\"\\n\", \",\")\n",
    "    tokens = ret.split(\",\")\n",
    "    idx = tokens.index(\"  Df Residuals:      \")\n",
    "    val = int(tokens[idx + 1])\n",
    "    assert val == 806, f\"{val} should be 806\"\n",
    "    idx = tokens.index(\"  Pseudo R-squ.:     \")\n",
    "    val = float(tokens[idx + 1])\n",
    "    assert val == pytest.approx(0.208, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "356bc420-8042-4441-84ce-369507b136e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:probit() outcome: pass; dof=806.0 >= 10\n",
      "INFO:acro::records:add(): output_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497218\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "test_stata_probit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088eb32a-fbec-4ab4-9955-93b20a659bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_print_outputs():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"print_outputs\",\n",
    "        varlist=\" inc_activity inc_grants inc_donations total_costs\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    assert len(ret) == 0, \"return string should  be empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec339b36-57eb-4f39-9d25-3b4f0117e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_0:\n",
      "uid: output_0\n",
      "status: fail\n",
      "type: table\n",
      "properties: {'method': 'crosstab', 'negative': False, 'missing': False, 'threshold': 2, 'p-ratio': 0, 'nk-rule': 0}\n",
      "command: safe_output = myacro.crosstab(\n",
      "summary: fail; threshold: 2 cells suppressed; \n",
      "outcome: {'G': {'Dead in 2015': 'ok', 'Alive in 2015': 'ok'}, 'N': {'Dead in 2015': 'threshold; ', 'Alive in 2015': 'ok'}, 'R': {'Dead in 2015': 'ok', 'Alive in 2015': 'ok'}, 'R/G': {'Dead in 2015': 'threshold; ', 'Alive in 2015': 'ok'}}\n",
      "output: [grant_type      G      N    R   R/G\n",
      "survivor                           \n",
      "Dead in 2015   18    NaN  282   NaN\n",
      "Alive in 2015  72  354.0  144  48.0]\n",
      "timestamp: 2023-06-29T15:33:57.492603\n",
      "comments: []\n",
      "\n",
      "\n",
      "output_1:\n",
      "uid: output_1\n",
      "status: pass\n",
      "type: regression\n",
      "properties: {'method': 'ols', 'dof': 807.0}\n",
      "command: results = myacro.ols(y, x)\n",
      "summary: pass; dof=807.0 >= 10\n",
      "outcome: {}\n",
      "output: [                       inc_activity           R-squared:      0.894\n",
      "Dep. Variable:                                                     \n",
      "Model:                          OLS      Adj. R-squared:      0.894\n",
      "Method:               Least Squares         F-statistic:   2276.000\n",
      "Date:              Thu, 29 Jun 2023  Prob (F-statistic):      0.000\n",
      "Time:                      15:34:04      Log-Likelihood: -14493.000\n",
      "No. Observations:               811                 AIC:  28990.000\n",
      "Df Residuals:                   807                 BIC:  29010.000\n",
      "Df Model:                         3                  NaN        NaN\n",
      "Covariance Type:          nonrobust                  NaN        NaN,                       coef     std err       t  P>|t|      [0.025       0.975]\n",
      "const          399400.0000  531000.000   0.752  0.452 -643000.000  1440000.000\n",
      "inc_grants         -0.8856       0.025 -36.128  0.000      -0.934       -0.837\n",
      "inc_donations      -0.6659       0.016 -40.905  0.000      -0.698       -0.634\n",
      "total_costs         0.8318       0.011  78.937  0.000       0.811        0.853,                 1348.637     Durbin-Watson:         1.424\n",
      "Omnibus:                                                 \n",
      "Prob(Omnibus):     0.000  Jarque-Bera (JB):  1.298162e+06\n",
      "Skew:             10.026          Prob(JB):  0.000000e+00\n",
      "Kurtosis:        197.973          Cond. No.  1.060000e+08]\n",
      "timestamp: 2023-06-29T15:34:04.683974\n",
      "comments: []\n",
      "\n",
      "\n",
      "output_2:\n",
      "uid: output_2\n",
      "status: pass\n",
      "type: regression\n",
      "properties: {'method': 'probit', 'dof': 806.0}\n",
      "command: results = myacro.probit(y, x)\n",
      "summary: pass; dof=806.0 >= 10\n",
      "outcome: {}\n",
      "output: [                          survivor No. Observations:           811\n",
      "Dep. Variable:                                                    \n",
      "Model:                      Probit     Df Residuals:  8.060000e+02\n",
      "Method:                        MLE         Df Model:  4.000000e+00\n",
      "Date:             Thu, 29 Jun 2023    Pseudo R-squ.:  2.086000e-01\n",
      "Time:                     15:34:11   Log-Likelihood: -4.032400e+02\n",
      "converged:                    True          LL-Null: -5.095000e+02\n",
      "Covariance Type:         nonrobust      LLR p-value:  7.648000e-45,                        coef       std err      z  P>|z|        [0.025  \\\n",
      "const          4.450000e-02  5.600000e-02  0.791  0.429 -6.600000e-02   \n",
      "inc_activity   4.114000e-08  6.540000e-08  0.629  0.530 -8.710000e-08   \n",
      "inc_grants    -4.297000e-08  6.070000e-08 -0.708  0.479 -1.620000e-07   \n",
      "inc_donations  1.357000e-07  6.270000e-08  2.163  0.031  1.280000e-08   \n",
      "total_costs    3.473000e-08  5.840000e-08  0.595  0.552 -7.960000e-08   \n",
      "\n",
      "                     0.975]  \n",
      "const          1.550000e-01  \n",
      "inc_activity   1.690000e-07  \n",
      "inc_grants     7.600000e-08  \n",
      "inc_donations  2.590000e-07  \n",
      "total_costs    1.490000e-07  ]\n",
      "timestamp: 2023-06-29T15:34:11.291471\n",
      "comments: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_stata_print_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a9a34e6-3b72-467d-b265-e1c6677ea537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stata_finalise():\n",
    "    ret = dummy_acrohandler(\n",
    "        command=\"finalise\",\n",
    "        varlist=\"\",\n",
    "        exclusion=\"\",\n",
    "        exp=\"\",\n",
    "        weights=\"\",\n",
    "        options=\"\",\n",
    "    )\n",
    "    correct = \"outputs and stata_out.json written\\n\"\n",
    "    assert ret == correct, f\"returned string {ret} should be {correct}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edf066a6-029b-4934-a233-f2352b698a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro::records:outputs written to: stata_out.json\n"
     ]
    }
   ],
   "source": [
    "test_stata_finalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3244415-990f-461b-8618-51844ac4cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find_brace_contents():\n",
    "    options = \"by(grant_type) \" \"contents(mean sd inc_activity)\" \"suppress \" \"nototals\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"by\", options)\n",
    "    assert res == True\n",
    "    assert substr == \"grant_type\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"contents\", options)\n",
    "    assert res == True\n",
    "    assert substr == \"mean sd inc_activity\"\n",
    "    res, substr = acro_stata_parser.find_brace_contents(\"foo\", options)\n",
    "    assert res == False\n",
    "    assert substr == \"foo not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24340292-cbc5-4ff8-96f4-dddd3ade650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_find_brace_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04c1f74b-2c82-4673-861a-ff749260204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unsupported_formatting_options():\n",
    "    path = os.path.join(\"../data\", \"test_data.dta\")\n",
    "    df = pd.read_stata(path)\n",
    "    format_string = \"acro does not currently support table formatting commands.\"\n",
    "    correct = pd.crosstab(index=df[\"survivor\"], columns=df[\"grant_type\"]).to_string()\n",
    "    for bad_option in [\n",
    "        \"cellwidth\",\n",
    "        \"csepwidth\",\n",
    "        \"stubwidth\",\n",
    "        \"scsepwidth\",\n",
    "        \"center\",\n",
    "        \"left\",\n",
    "    ]:\n",
    "        ret = dummy_acrohandler(\n",
    "            \"table\",\n",
    "            \"survivor grant_type\",\n",
    "            exclusion=\"\",\n",
    "            exp=\"\",\n",
    "            weights=\"\",\n",
    "            options=f\"{bad_option} nototals\",\n",
    "        )\n",
    "\n",
    "        rets = ret.split(\"\\n\", 1)\n",
    "        assert len(rets) == 2, \"table should have warning preprended\"\n",
    "        errmsg = f\"first line {rets[0]} should be {format_string}\"\n",
    "        assert rets[0] == format_string, errmsg\n",
    "        ret = rets[1]\n",
    "        ret = ret.replace(\"NaN\", \"0\")\n",
    "        ret = ret.replace(\".0\", \"\")\n",
    "        assert ret.split() == correct.split(), f\"got\\n{ret}\\n expected\\n{correct}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a93d307-dc11-4766-ac91-c3c580ff0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_21\n",
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_22\n",
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_23\n",
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_24\n",
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_25\n",
      "INFO:acro:outcome_df:\n",
      "grant_type      G            N   R          R/G\n",
      "survivor                                       \n",
      "Dead in 2015   ok  threshold;   ok  threshold; \n",
      "Alive in 2015  ok           ok  ok           ok\n",
      "INFO:acro:get_summary(): fail; threshold: 2 cells suppressed; \n",
      "INFO:acro::records:add(): output_26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed first part\n",
      "passed first part\n",
      "passed first part\n",
      "passed first part\n",
      "passed first part\n",
      "passed first part\n"
     ]
    }
   ],
   "source": [
    "test_unsupported_formatting_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a11dab-f605-479b-b5c9-6cbe61280fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint1",
   "language": "python",
   "name": "sprint1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
